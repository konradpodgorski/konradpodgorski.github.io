<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title><![CDATA[Konrad Podgórski - Web Developer]]></title>
    <link href="http://konradpodgorski.com/atom.xml" rel="self"/>
    <link href="http://konradpodgorski.com/"/>
    <updated>2014-06-30T23:54:05+02:00</updated>
    <id>http://konradpodgorski.com/</id>
            <author>
            <name><![CDATA[Konrad Podgórski]]></name>                    </author>
        <generator uri="http://sculpin.io/">Sculpin</generator>
            <entry>
            <title type="html"><![CDATA[A better way to work with assets in Symfony 2]]></title>
            <link href="http://konradpodgorski.com/blog/2014/06/23/better-way-to-work-with-assets-in-symfony-2"/>
            <updated>2014-06-26T18:14:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2014/06/23/better-way-to-work-with-assets-in-symfony-2</id>
            <content type="html"><![CDATA[<p>I will explain how to work with assets in Symfony framework without having to use Assetic Bundle at all.</p>

<blockquote>
  <p>We will build a stack that will</p>
  
  <ul>
  <li>download and prepare dependencies (jQuery, Bootstrap and Font Awesome icons)</li>
  <li>merge and minify css and javascript files</li>
  <li>copy necessary fonts (font-awesome) in the right place so the path in css is correct</li>
  <li>automate deploy to S3 bucket which you can optionally convert to CDN</li>
  </ul>
</blockquote>

<p><div class="sharing">
    <a href="//twitter.com/share" class="twitter-share-button" data-url="http://konradpodgorski.com/blog/2014/06/23/better-way-to-work-with-assets-in-symfony-2" data-via="konradpodgorski" data-counturl="http://konradpodgorski.com/blog/2014/06/23/better-way-to-work-with-assets-in-symfony-2" >Tweet</a>
      <div class="g-plusone" data-size="medium"></div>
        <div class="fb-like" data-layout="button_count" data-action="like" data-show-faces="false" data-share="true"></div>
  </div>
</p>

<p>The process will be really fast and easy to understand even if you never used software listed here. However if you experience any problems do not hesitate to ask for help in comments.
Post is quite long because it contain a lot of different configs but don't run away just yet. They are ready to copy &amp; paste.</p>

<p>Also ... I'm working with Symfony here but you can use it for literally any other web framework.</p>

<h2>Table of contents</h2>

<blockquote>
  <ol>
  <li><a href="#introduction">Introduction</a></li>
  <li>Prerequisites
  
  <ol>
  <li><a href="#nodejs">Installing NodeJS</a></li>
  <li><a href="#bower">Installing Bower</a></li>
  <li><a href="#gruntjs">Installing GruntJS</a></li>
  </ol></li>
  <li>Use cases
  
  <ol>
  <li><a href="#scenario-1">Scenario</a> - download dependencies and copy them to <code>/web/assets/*</code> dir</li>
  <li><a href="#scenario-2">Scenario</a> - download dependencies, copy and minify them</li>
  <li><a href="#scenario-3">Scenario</a> - download, copy, concat (merge) and minify</li>
  <li><a href="#deploy-to-cdn">Deploying to S3/CDN</a> - all above plus automated deploy to the CDN</li>
  </ol></li>
  </ol>
</blockquote>

<h1 id="introduction">Introduction</h1>

<p>Why you would want to do it?</p>

<ul>
<li>assets are generated on your computer once, so the server doesn't have to do anything (less software on server = the better)</li>
<li>if you are (or will be) using load balancer you definitely should (actually must) keep assets on CDN</li>
<li>one less bundle to load in your Symfony application (Assetic)</li>
</ul>

<p>What we will use?
NodeJS, Bower, Grunt JS and some grunt tasks</p>

<p>Before we begin please add these to your <code>.gitignore</code> file, you don't want to keep vendor libraries in your repository.</p>

<pre><code>bower_components/
node_modules/
</code></pre>

<h2 id="nodejs">Install NodeJS</h2>

<p>NodeJS is a runtime platform for applications written in javascript, it's required by Bower and GruntJs we will install in a moment.</p>

<p>Those who already have node js installed can go to the next step</p>

<blockquote>
  <p><a href="/blog/2014/06/22/how-to-install-node-js">How to install Node JS</a></p>
</blockquote>

<h2 id="bower">Installing Bower</h2>

<p>Bower is like a composer for frontend libraries. If you like composer you will definitely like Bower.</p>

<pre><code>npm install -g bower
</code></pre>

<p>Create file <code>bower.json</code>, it will hold information about all required dependencies.</p>

<pre><code>{
    "name": "symfony-application",
    "dependencies": {
        "jquery": "1.11.*",
        "bootstrap": "3.1.*",
        "font-awesome": "4.1.*"
    }
}
</code></pre>

<p>run bower install</p>

<pre><code>bower install
</code></pre>

<p>Folder structure will look like this</p>

<pre><code>.
├── bower_components
│   ├── bootstrap
│   ├── font-awesome
│   └── jquery
├── bower.json
└── .gitignore
</code></pre>

<h2 id="gruntjs">Installing Grunt JS</h2>

<p>GruntJS is our task runner, by adding a set of tasks created by Grunt community we can automate many tasks we used to do manually with a very little effort.</p>

<p>To install it we will once again use node package manager, npm:</p>

<pre><code>npm install -g grunt-cli
</code></pre>

<p>Create file <code>package.json</code>, it will hold all dependencies for grunt tasks</p>

<pre><code>{
  "name": "symfony-application",
  "version": "0.1.0"
}
</code></pre>

<p>Run the following commands (<code>--save-dev</code> option will add it to <code>package.json</code>)</p>

<pre><code>npm install grunt --save-dev
npm install grunt-bowercopy --save-dev
npm install grunt-contrib-clean --save-dev
npm install grunt-contrib-concat --save-dev
npm install grunt-contrib-copy --save-dev
npm install grunt-contrib-cssmin --save-dev
npm install grunt-contrib-uglify --save-de
npm install grunt-contrib-watch --save-dev
</code></pre>

<p>Now <code>package.json</code> should look like this.</p>

<pre><code>{
  "name": "symfony-application",
  "version": "0.1.0",
  "devDependencies": {
    "grunt": "^0.4.5",
    "grunt-bowercopy": "^1.0.1",
    "grunt-contrib-clean": "^0.5.0",
    "grunt-contrib-concat": "^0.4.0",
    "grunt-contrib-copy": "^0.5.0",
    "grunt-contrib-cssmin": "^0.10.0",
    "grunt-contrib-uglify": "^0.5.0",
    "grunt-contrib-watch": "^0.6.1"
  }
}
</code></pre>

<p>Once <code>package.json</code> is updated in the future you can use simple <code>npm install</code> to install grunt dependencies</p>

<p>Now when all dependencies are ready we can configure how we want assets to be processed.</p>

<h2 id="scenario-1">Scenario 1</h2>

<p>Download latest jQuery, Bootstrap, Font Awesome with Bower and copy the only necessary files to <code>web/assets/*</code></p>

<p>Create file <code>Gruntfile.js</code>, it will contain all configurations</p>

<pre><code class="js">module.exports = function (grunt) {
    grunt.initConfig({
        pkg: grunt.file.readJSON('package.json'),
        bowercopy: {
            options: {
                srcPrefix: 'bower_components',
                destPrefix: 'web/assets'
            },
            scripts: {
                files: {
                    'js/jquery.js': 'jquery/dist/jquery.js',
                    'js/bootstrap.js': 'bootstrap/dist/js/bootstrap.js'
                }
            },
            stylesheets: {
                files: {
                    'css/bootstrap.css': 'bootstrap/dist/css/bootstrap.css',
                    'css/font-awesome.css': 'font-awesome/css/font-awesome.css'
                }
            },
            fonts: {
                files: {
                    'fonts': 'font-awesome/fonts'
                }
            }
        }
    });

    grunt.loadNpmTasks('grunt-bowercopy');
    grunt.registerTask('default', ['bowercopy']);
};
</code></pre>

<p>Run grunt with simple</p>

<pre><code>grunt
</code></pre>

<p>It will fetch latest dependencies with Bower and copy them to desired locations</p>

<pre><code>web
└── assets
    ├── css
    │   ├── bootstrap.css
    │   └── font-awesome.css
    ├── fonts
    │   ├── FontAwesome.otf
    │   ├── fontawesome-webfont.eot
    │   ├── fontawesome-webfont.svg
    │   ├── fontawesome-webfont.ttf
    │   └── fontawesome-webfont.woff
    └── js
        ├── bootstrap.js
        └── jquery.js
</code></pre>

<h2 id="scenario-2">Scenario 2</h2>

<p>Download dependencies with Bower, copy necessary files to <code>web/assets/*</code>. Then minify javascript and stylesheet files.</p>

<blockquote>
  <p>Although most frontend libraries comes with both normal and minified versions we will do it for the sake of learning.</p>
</blockquote>

<p>Update <code>Gruntfile.js</code> you created in previous scenario with configuration for <code>cssmin</code> and <code>uglify</code></p>

<pre><code>module.exports = function (grunt) {
    grunt.initConfig({
        pkg: grunt.file.readJSON('package.json'),
        bowercopy: {
            options: {
                srcPrefix: 'bower_components',
                destPrefix: 'web/assets'
            },
            scripts: {
                files: {
                    'js/jquery.js': 'jquery/dist/jquery.js',
                    'js/bootstrap.js': 'bootstrap/dist/js/bootstrap.js'
                }
            },
            stylesheets: {
                files: {
                    'css/bootstrap.css': 'bootstrap/dist/css/bootstrap.css',
                    'css/font-awesome.css': 'font-awesome/css/font-awesome.css'
                }
            },
            fonts: {
                files: {
                    'fonts': 'font-awesome/fonts'
                }
            }
        },
        cssmin : {
            bootstrap:{
                src: 'web/assets/css/bootstrap.css',
                dest: 'web/assets/css/bootstrap.min.css'
            },
            "font-awesome":{
                src: 'web/assets/css/font-awesome.css',
                dest: 'web/assets/css/font-awesome.min.css'
            }
        },
        uglify : {
            js: {
                files: {
                    'web/assets/js/jquery.min.js': ['web/assets/js/jquery.js'],
                    'web/assets/js/bootstrap.min.js': ['web/assets/js/bootstrap.js']
                }
            }
        }
    });

    grunt.loadNpmTasks('grunt-bowercopy');
    grunt.loadNpmTasks('grunt-contrib-cssmin');
    grunt.loadNpmTasks('grunt-contrib-uglify');

    grunt.registerTask('default', ['bowercopy', 'cssmin', 'uglify']);
};
</code></pre>

<p>Run grunt by typing <code>grunt</code> and the the structure should look like this</p>

<pre><code>web
└── assets
    ├── css
    │   ├── bootstrap.css
    │   ├── bootstrap.min.css
    │   ├── font-awesome.css
    │   └── font-awesome.min.css
    ├── fonts
    │   ├── FontAwesome.otf
    │   ├── fontawesome-webfont.eot
    │   ├── fontawesome-webfont.svg
    │   ├── fontawesome-webfont.ttf
    │   └── fontawesome-webfont.woff
    └── js
        ├── bootstrap.js
        ├── bootstrap.min.js
        ├── jquery.js
        └── jquery.min.js
</code></pre>

<h2 id="scenario-3">Scenario 3</h2>

<p>Download dependencies with Bower, merge them with your custom css and js files, then minify.</p>

<p>Assume we have the following structure</p>

<pre><code>src
└── KP
    └── LearningBundle
        └── Resources
            └── public
                ├── css
                │   └── main.css
                ├── images
                │   └── no-photo.gif
                └── js
                    ├── editor.js
                    └── notification.js
</code></pre>

<p>First task we configure will be <code>copy</code>, it will copy image(s) to <code>web/assets/images/*</code> directory.
 Second task we will add is <code>concat</code>, it will merge all scripts into single file which we will later <code>uglify</code> to make it smaller
  Same thing for stylesheet file</p>

<p>Updated <code>Gruntfile.js</code></p>

<pre><code>module.exports = function (grunt) {
    grunt.initConfig({
        pkg: grunt.file.readJSON('package.json'),
        bowercopy: {
            options: {
                srcPrefix: 'bower_components',
                destPrefix: 'web/assets'
            },
            scripts: {
                files: {
                    'js/jquery.js': 'jquery/dist/jquery.js',
                    'js/bootstrap.js': 'bootstrap/dist/js/bootstrap.js'
                }
            },
            stylesheets: {
                files: {
                    'css/bootstrap.css': 'bootstrap/dist/css/bootstrap.css',
                    'css/font-awesome.css': 'font-awesome/css/font-awesome.css'
                }
            },
            fonts: {
                files: {
                    'fonts': 'font-awesome/fonts'
                }
            }
        },
        cssmin : {
            bundled:{
                src: 'web/assets/css/bundled.css',
                dest: 'web/assets/css/bundled.min.css'
            }
        },
        uglify : {
            js: {
                files: {
                    'web/assets/js/bundled.min.js': ['web/assets/js/bundled.js']
                }
            }
        },
        concat: {
            options: {
                stripBanners: true
            },
            css: {
                src: [
                    'web/assets/css/bootstrap.css',
                    'web/assets/css/font-awesome.css',
                    'src/KP/LearningBundle/Resources/public/css/*.css'
                ],
                dest: 'web/assets/css/bundled.css'
            },
            js : {
                src : [
                    'web/assets/js/jquery.js',
                    'web/assets/js/bootstrap.js',
                    'src/KP/LearningBundle/Resources/public/js/*.js'
                ],
                dest: 'web/assets/js/bundled.js'
            }
        },
        copy: {
            images: {
                expand: true,
                cwd: 'src/KP/LearningBundle/Resources/public/images',
                src: '*',
                dest: 'web/assets/images/'
            }
        }
    });

    grunt.loadNpmTasks('grunt-bowercopy');
    grunt.loadNpmTasks('grunt-contrib-concat');
    grunt.loadNpmTasks('grunt-contrib-copy');
    grunt.loadNpmTasks('grunt-contrib-cssmin');
    grunt.loadNpmTasks('grunt-contrib-uglify');

    grunt.registerTask('default', ['bowercopy','copy', 'concat', 'cssmin', 'uglify']);
};
</code></pre>

<h1 id="deploy-to-cdn">Deploy to S3/CDN</h1>

<p>Cloudfront is one of the most popular and in my opinion one of the easiest to begin with cdn servers
Uploading assets to S3 storage and setting it as a source for CDN is enough to get started.</p>

<p>S3 Integration is handled by another grunt task we will add to our stack</p>

<pre><code>npm install grunt-s3 --save-dev
</code></pre>

<p>You can find the full documentation on the official repository <a href="https://github.com/pifantastic/grunt-s3">https://github.com/pifantastic/grunt-s3</a></p>

<p>We will only use upload feature.</p>

<p>Create a new file where you will store credentials to the S3 bucket. Lets call it <code>aws-credentials.json</code></p>

<p>Don't forget to add it to <code>.gitignore</code>, last thing you want to do is to push your key/secret to the repository.</p>

<pre><code># .gitignore
bower_components/
node_modules/
aws-credentials.json
</code></pre>

<p>and the content of <code>aws-credentials.json</code> should be like this</p>

<pre><code class="json">{
    "key": "your_aws_key",
    "secret": "your_aws_secret",
    "bucket": "name_of_your_bucket"
}
</code></pre>

<p>Updated <code>Gruntfile.js</code> with <code>grunt-s3</code> task</p>

<pre><code class="js">module.exports = function (grunt) {
    grunt.initConfig({
        pkg: grunt.file.readJSON('package.json'),
        bowercopy: {
            options: {
                srcPrefix: 'bower_components',
                destPrefix: 'web/assets'
            },
            scripts: {
                files: {
                    'js/jquery.js': 'jquery/dist/jquery.js',
                    'js/bootstrap.js': 'bootstrap/dist/js/bootstrap.js'
                }
            },
            stylesheets: {
                files: {
                    'css/bootstrap.css': 'bootstrap/dist/css/bootstrap.css',
                    'css/font-awesome.css': 'font-awesome/css/font-awesome.css'
                }
            },
            fonts: {
                files: {
                    'fonts': 'font-awesome/fonts'
                }
            }
        },
        cssmin : {
            bundled:{
                src: 'web/assets/css/bundled.css',
                dest: 'web/assets/css/bundled.min.css'
            }
        },
        uglify : {
            js: {
                files: {
                    'web/assets/js/bundled.min.js': ['web/assets/js/bundled.js']
                }
            }
        },
        concat: {
            options: {
                stripBanners: true
            },
            css: {
                src: [
                    'web/assets/css/bootstrap.css',
                    'web/assets/css/font-awesome.css',
                    'src/KP/LearningBundle/Resources/public/css/*.css'
                ],
                dest: 'web/assets/css/bundled.css'
            },
            js : {
                src : [
                    'web/assets/js/jquery.js',
                    'web/assets/js/bootstrap.js',
                    'src/KP/LearningBundle/Resources/public/js/*.js'
                ],
                dest: 'web/assets/js/bundled.js'
            }
        },
        copy: {
            images: {
                expand: true,
                cwd: 'src/KP/LearningBundle/Resources/public/images',
                src: '*',
                dest: 'web/assets/images/'
            }
        },
        aws: grunt.file.readJSON('aws-credentials.json'),
        s3: {
            options: {
                key: '&lt;%= aws.key %&gt;',
                secret: '&lt;%= aws.secret %&gt;',
                bucket: '&lt;%= aws.bucket %&gt;'
            },
            cdn: {
                upload: [
                    {
                        src: 'web/assets/css/*',
                        dest: 'css/'
                    },

                    {
                        src: 'web/assets/fonts/*',
                        dest: 'fonts/'
                    },
                    {
                        src: 'web/assets/images/*',
                        dest: 'images/'
                    },
                    {
                        src: 'web/assets/js/*',
                        dest: 'js/'
                    }
                ]
            }
        }
    });

    grunt.loadNpmTasks('grunt-bowercopy');
    grunt.loadNpmTasks('grunt-contrib-concat');
    grunt.loadNpmTasks('grunt-contrib-copy');
    grunt.loadNpmTasks('grunt-contrib-cssmin');
    grunt.loadNpmTasks('grunt-contrib-uglify');
    grunt.loadNpmTasks('grunt-s3');

    grunt.registerTask('default', ['bowercopy','copy', 'concat', 'cssmin', 'uglify']);
    grunt.registerTask('deploy', ['s3']);
};
</code></pre>

<p>Now you can generate assets like you did until now with command <code>grunt</code>, but also deploy them directly to the CDN with command <code>grunt:deploy</code>.</p>

<pre><code class="shell">grunt
grunt:deploy
</code></pre>

<h1>What next?</h1>

<p>Article is already pretty long and I still didn't cover everything I wanted. There will be another part of this article that will cover</p>

<ul>
<li>Working with less/sass</li>
<li>Automated cleaning legacy assets</li>
<li>Watching for changes in assets</li>
<li>Better explain how to correctly configure S3 bucket to act as a CDN</li>
<li>How to use Require JS (the most interesting topic)</li>
<li>Disabling Assetic Bundle from Symfony application</li>
</ul>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Fixing the locale problem in Debian - mirror]]></title>
            <link href="http://konradpodgorski.com/blog/2014/06/23/fixing-locale-problem-debian"/>
            <updated>2014-06-23T10:12:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2014/06/23/fixing-locale-problem-debian</id>
            <content type="html"><![CDATA[<blockquote>
  <p>Post was originally posted on <a href="http://hexample.com/2012/02/05/fixing-locale-problem-debian/">http://hexample.com/2012/02/05/fixing-locale-problem-debian/</a></p>
  
  <p>I was using this tutorial for a very long time, it was also linked from my other posts. However in last month I noticed it's no longer available.
  Full credit for this awesome tutorial goes to Crypto, the original author.</p>
</blockquote>

<p>People who aren’t using the default locales (en_US) on their Debian based servers, often see error messages like perl: warning: Setting locale failed or perl: warning: Falling back to the standard locale (“C”). A listing of the complete error message is given in the full article. The error messages appear when installing packages with apt-get or when using some common perl commands like auto completion. On the internet you find a lot of different solutions that may work. This tutorial gives a more comprehensive approach to the matter. This way you understand the error and you are able to fight this annoying error message.</p>

<p>This little tutorial and fix is for everyone who gets following error code.</p>

<pre><code class="shell">perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
        LANGUAGE = (unset),
        LC_ALL = (unset),
        LC_CTYPE = "UTF-8",
        LANG = "en_US"
    are supported and installed on your system.

locale: Cannot set LC_CTYPE to default locale: No such file or directory
locale: Cannot set LC_MESSAGES to default locale: No such file or directory
locale: Cannot set LC_ALL to default locale: No such file or directory
</code></pre>

<h2>Quick checklist</h2>

<ol>
<li>Check if locales is installed</li>
<li>Check the used/needed locales</li>
<li>Check the available locales</li>
<li>Generate all needed locales</li>
<li>Log out and back in</li>
</ol>

<h2>Full explanation</h2>

<p>On the internet you will find fixes that tell you to do dpkg-reconfigure or locales-gen. They are correct, but aren’t enough if you do it brainlessly. What you have to do is first check if the locales package is installed.</p>

<pre><code>apt-get install locales
</code></pre>

<p>In most cases it will report that locales is already installed and up to date.</p>

<p>Second, what most how-to’s and fixes forget to mention, it is very important to know which locales are needed by the system.</p>

<pre><code>sudo locale
</code></pre>

<p>By running this command, you will get a list of every needed locale. It is important to write down the locales other than en_US. On my system there was an extra locale nl_NL.UTF-8.</p>

<p>Now, you have to check which locale is already present on the system. Do this by running the following listing.</p>

<pre><code>sudo locale -a
</code></pre>

<p>Normally you will see some English locales. But your extra locales are probably missing.</p>

<p>You have two options to add those extras. The first one is locale-gen, the second one is dpkg-reconfigure. I advise the latter if it is present on your system. I will discuss the two solutions.</p>

<pre><code>dpkg-reconfigure

sudo dpkg-reconfigure locales
</code></pre>

<p>First you’ll get a menu in which you have to select all needed locales. Select the English ones AND your extras with the space-bar.</p>

<p>In the next window select en_US.UTF-8 as default locale.</p>

<p>After regenerating the locales log out and back in. Your problem is solved!</p>

<pre><code>locale-gen
</code></pre>

<p>If for some reason dpkg-reconfigure is not available on your environment or your local user doesn’t have admin privileges, you can always use locale-gen. Use this command and append every extra locale you need.</p>

<p>If you need the nl_NL.UTF-8 locale:</p>

<pre><code>locale-gen nl_NL.UTF-8
</code></pre>

<p>Repeat this step for every locale you need. You can check if it was successful by running locale -a. Normally all your generated locales should be listed. Log out and back in to activate the new locales for your session.</p>

<h2>Conclusion</h2>

<p>I hope this quick fix helped you to fix the annoying missing locale bug. If you find it helpful or have some questions, please leave a message below.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How to install Node JS on Debian/Ubuntu]]></title>
            <link href="http://konradpodgorski.com/blog/2014/06/22/how-to-install-node-js"/>
            <updated>2014-06-22T22:35:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2014/06/22/how-to-install-node-js</id>
            <content type="html"><![CDATA[<p>Installing Node JS from source is very simple, although it might take some time to compile.</p>

<pre><code>sudo apt-get update
sudo apt-get install -y gcc g++ make
</code></pre>

<p><strike>At the time of writing this post the latest version of node is <code>v0.10.29</code>. To find the latest number you can go to
 <a href="http://nodejs.org/dist/latest/">http://nodejs.org/dist/latest/</a> and search for file matching pattern <code>node-v0.*.*.tar.gz</code></strike></p>

<p><strong>Update</strong>: permalink to the latest version of node is <a href="http://nodejs.org/dist/node-latest.tar.gz">http://nodejs.org/dist/node-latest.tar.gz</a></p>

<pre><code>wget http://nodejs.org/dist/node-latest.tar.gz
tar -zxvf node-latest.tar.gz
cd node-v*
./configure
make
sudo make install
</code></pre>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How to record a screencast under Ubuntu]]></title>
            <link href="http://konradpodgorski.com/blog/2014/06/06/how-to-record-a-screencast-under-ubuntu"/>
            <updated>2014-06-06T22:31:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2014/06/06/how-to-record-a-screencast-under-ubuntu</id>
            <content type="html"><![CDATA[<h3>Simplest solution to record a screencast in Ubuntu</h3>

<pre><code>sudo apt-get install recordmydesktop
</code></pre>

<p>Start recording with 10 second delay with this command</p>

<pre><code>recordmydesktop --width 1280 --height 720 --full-shots --fps 15 --no-sound --delay 10
</code></pre>

<p>Don't forget to adjust resolution first.</p>

<p><strong>Note:</strong> In general, recording a screencast in Full HD is not very good idea. Most of people will view it on youtube and fonts will be too small to read without switching to full screen.
I recommend reserving some fixed space on the screen for recording and adjusting recording position with <code>--width</code>, <code>--height</code>, <code>-x</code> and <code>-y</code> parameters.
In my opinion using resolution <code>1280x720px</code> is a good choice.</p>

<p>Reference</p>

<pre><code>Usage: recordmydesktop [OPTIONS]^filename

Generic Options
  -h, --help                              Print this help and exit.
      --version                           Print program version and exit.
      --print-config                      Print info about options selected
                                          during compilation and exit.

Image Options
      --windowid=id_of_window             id of window to be recorded.
      --display=DISPLAY                   Display to connect to.
  -x, --x=N&gt;=0                            Offset in x direction.
  -y, --x=N&gt;=0                            Offset in y direction.
      --width=N&gt;0                         Width of recorded window.
      --height=N&gt;0                        Height of recorded window.
      --dummy-cursor=color                Color of the dummy cursor
                                          [black|white]
      --no-cursor                         Disable drawing of the cursor.
      --no-shared                         Disable usage of MIT-shared memory
                                          extension(Not Recommended!).
      --full-shots                        Take full screenshot at every
                                          frame(Not recomended!).
      --follow-mouse                      Makes the capture area follow the
                                          mouse cursor. Autoenables
                                          --full-shots.
      --quick-subsampling                 Do subsampling of the chroma planes
                                          by discarding, not averaging.
      --fps=N(number&gt;0.0)                 A positive number denoting desired
                                          framerate.

Sound Options
      --channels=N                        A positive number denoting desired
                                          sound channels in recording.
      --freq=N                            A positive number denoting desired
                                          sound frequency.
      --buffer-size=N                     A positive number denoting the
                                          desired sound buffer size (in
                                          frames,when using ALSA or OSS)
      --ring-buffer-size=N                A float number denoting the desired
                                          ring buffer size (in seconds,when
                                          using JACK only).
      --device=SOUND_DEVICE               Sound device(default default).
      --use-jack=port1 port2... portn     Record audio from the specified list
                                          of space-separated jack ports.
      --no-sound                          Do not record sound.

Encoding Options
      --on-the-fly-encoding               Encode the audio-video data, while
                                          recording.
      --v_quality=n                       A number from 0 to 63 for desired
                                          encoded video quality(default 63).
      --v_bitrate=n                       A number from 0 to 2000000 for
                                          desired encoded video
                                          bitrate(default 0).
      --s_quality=n                       Desired audio quality(-1 to 10).

Misc Options
      --rescue=path_to_data               Encode data from a previous,
                                          crashed, session.
      --no-wm-check                       Do not try to detect the window
                                          manager(and set options according to
                                          it)
      --no-frame                          Don not show the frame that
                                          visualizes the recorded area.
      --pause-shortcut=MOD+KEY            Shortcut that will be used for
                                          (un)pausing (default Control+Mod1+p).
      --stop-shortcut=MOD+KEY             Shortcut that will be used to stop
                                          the recording (default
                                          Control+Mod1+s).
      --compress-cache                    Image data are cached with light
                                          compression.
      --workdir=DIR                       Location where a temporary directory
                                          will be created to hold project
                                          files(default $HOME).
      --delay=n[H|h|M|m]                  Number of secs(default),minutes or
                                          hours before capture starts(number
                                          can be float)
      --overwrite                         If there is already a file with the
                                          same name, delete it (default is to
                                          add a number postfix to the new one).
  -o, --output=filename                   Name of recorded video(default
                                          out.ogv).

    If no other options are specified, filename can be given without the -o switch.
</code></pre>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[[Solution] Couldn&#039;t find constant Monolog\Logger::DEBUG]]></title>
            <link href="http://konradpodgorski.com/blog/2014/03/25/solution-to-couldnt-find-constant-monolog-logger-debug"/>
            <updated>2014-03-25T11:46:00+01:00</updated>
            <id>http://konradpodgorski.com/blog/2014/03/25/solution-to-couldnt-find-constant-monolog-logger-debug</id>
            <content type="html"><![CDATA[<p>Note for others having same problem</p>

<pre><code>PHP Warning:  constant(): Couldn't find constant Monolog\Logger::DEBUG in [..] /vendor/symfony/monolog-bundle/Symfony/Bundle/MonologBundle/DependencyInjection/MonologExtension.php on line 110
</code></pre>

<p>This is because composer version you are running doesn\'t support PSR-4. to fix it update your composer with</p>

<pre><code>composer self-update
</code></pre>

<p>Credit:
https://groups.google.com/forum/?hl=en#!topic/symfony2/8cNR9IBjuDo</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How to validate emails outside of form with Symfony Validator Component]]></title>
            <link href="http://konradpodgorski.com/blog/2013/10/29/how-to-validate-emails-outside-of-form-with-symfony-validator-component"/>
            <updated>2013-10-29T14:09:00+01:00</updated>
            <id>http://konradpodgorski.com/blog/2013/10/29/how-to-validate-emails-outside-of-form-with-symfony-validator-component</id>
            <content type="html"><![CDATA[<p>I'm building an invitation mechanism where owner of group can invite one or many users by providing email address(es) through rest api.
 This is very simple using Symfony Validator Component, but I noticed strange behavior when running tests. If I do
  not pass any emails I get wrong status code. 200 OK instead of 400 bad request.</p>

<p>After a while I found that using only \Symfony\Component\Validator\Constraints\Email() is not enough. Validator will
 pass null values and empty string, which is obvious wrong in my case.
  I had to also add NotBlank constraint, don't forget that in future.</p>

<p>At first I thought that this is a bug, but since it's covered by separate 2 tests here
https://github.com/symfony/symfony/blob/master/src/Symfony/Component/Validator/Tests/Constraints/EmailValidatorTest.php#L35
I will leave it as it is.</p>

<p>Credit goes to the functional tests! :)</p>

<p>Snippet for further reference.</p>

<pre><code class="php">    /**
     * Validates single email (or an array of email addresses
     *
     * @param array|string $emails
     *
     * @return array
     */
    public function validateEmails($emails){

        $errors = array();
        $emails = is_array($emails) ? $emails : array($emails);

        $validator = $this-&gt;container-&gt;get('validator');

        $constraints = array(
            new \Symfony\Component\Validator\Constraints\Email(),
            new \Symfony\Component\Validator\Constraints\NotBlank()
        );

        foreach ($emails as $email) {

            $error = $validator-&gt;validateValue($email, $constraints);

            if (count($error) &gt; 0) {
                $errors[] = $error;
            }
        }

        return $errors;
    }
</code></pre>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Step by step guide how to configure server for PHP / Symfony project]]></title>
            <link href="http://konradpodgorski.com/blog/2013/10/23/guide-how-to-configure-server-for-symfony"/>
            <updated>2014-06-23T22:30:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2013/10/23/guide-how-to-configure-server-for-symfony</id>
            <content type="html"><![CDATA[<p>I decided to publish notes that I have been gathering lately about configuring servers.
This is a complete guide how to configure server for production usage with Symfony or any PHP project.
Instruction might seem to you very long and I totally agree with you. It took me few months to finish.</p>

<!-- more -->

<p>These steps are about preparing your server for PHP / Symfony application and do not cover code deployment itself.</p>

<p>If you found this useful leave a comment or share link to your friends, it's always good to know that someone (besides Googlebot) actually read this :)</p>

<p><div class="sharing">
    <a href="//twitter.com/share" class="twitter-share-button" data-url="http://konradpodgorski.com/blog/2013/10/23/guide-how-to-configure-server-for-symfony" data-via="konradpodgorski" data-counturl="http://konradpodgorski.com/blog/2013/10/23/guide-how-to-configure-server-for-symfony" >Tweet</a>
      <div class="g-plusone" data-size="medium"></div>
        <div class="fb-like" data-layout="button_count" data-action="like" data-show-faces="false" data-share="true"></div>
  </div>
</p>

<p><strong>All steps should be done in order of reading. Configuration should not take you more than two hours.
It was tested by me on ~10 machines, however if you find something not working don't hesitate to let me know.
I try to help you and correct/expand guide to cover your problem.</strong></p>

<p>Post index for quick navigation</p>

<ul>
<li><a href="#securing-server">Securing server</a></li>
<li><a href="#dotdeb">Dotdeb</a></li>
<li><a href="#nginx">Nginx</a></li>
<li><a href="#php-fpm">PHP fpm</a></li>
<li><a href="#mysql">MySQL</a></li>
<li><a href="#nodejs">NodeJS</a></li>
</ul>

<p>Requirements:</p>

<ul>
<li>OS: Debian 6.0 or 7.0</li>
</ul>

<p>You will get server with:</p>

<ul>
<li>Nginx (latest stable), using sockets to communicate with PHP rather than TCP/IP</li>
<li>PHP 5.4 or 5.5 (latest stable)</li>
<li>MySQL 5.5 (production settings)</li>
<li>NodeJS (latest stable), including: Less, Uglify-JS</li>
<li>Twig C extension</li>
<li>GIT</li>
<li>Optional: Zend OPCache, APCu</li>
</ul>

<p>Security:</p>

<ul>
<li>Disabled direct root access</li>
<li>Installed sudo</li>
<li>Installed fail2ban (deny access after 3 incorrect login attempts)</li>
<li>Non privileged user for deployments</li>
<li>Authorization using ssh keys</li>
</ul>

<p>Other</p>

<ul>
<li>Correct timezone</li>
<li>Fixed common locale warnings</li>
<li>Color prompt</li>
<li>Removed Apache2</li>
</ul>

<h1>Step by step guide how to configure server for PHP / Symfony project</h1>

<h3>Mass replace</h3>

<p>You can copy guide to your favorite editor and use mass replace function, this way later you can just copy paste all commands.</p>

<p>Use mass replace function to change following unique strings</p>

<ul>
<li>SERVERIPADDRESS to your actual IPv4 ip address</li>
<li>NONPRIVILAGEUNIXUSERNAME to unix username you want to use, e.g. konrad</li>
<li>APPDOMAINNAME to domain name without http:// and trailing slash e.g. konradpodgorski.com</li>
</ul>

<h1 id="securing-server">Securing server</h1>

<p>First log in</p>

<pre><code>ssh root@SERVERIPADDRESS
</code></pre>

<p>On server create new user</p>

<pre><code>useradd NONPRIVILAGEUNIXUSERNAME -m -s /bin/bash
</code></pre>

<h3>Update apt-get</h3>

<pre><code>apt-get update
</code></pre>

<h3>Install nano</h3>

<pre><code>apt-get install nano
</code></pre>

<h3>Install sudo</h3>

<pre><code>apt-get install sudo

nano /etc/sudoers
</code></pre>

<p>Before</p>

<pre><code>#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults        env_reset
Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root    ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:
</code></pre>

<p>After (added: <strong>NONPRIVILAGEUNIXUSERNAME    ALL=(ALL) NOPASSWD: ALL</strong>)</p>

<pre><code>#
# This file MUST be edited with the 'visudo' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults        env_reset
Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root    ALL=(ALL:ALL) ALL

NONPRIVILAGEUNIXUSERNAME    ALL=(ALL) NOPASSWD: ALL


# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:
</code></pre>

<h3>Switch user you just created</h3>

<pre><code>su NONPRIVILAGEUNIXUSERNAME
</code></pre>

<p>Add your public key to an authorized keys</p>

<pre><code>cd ~
mkdir .ssh
nano .ssh/authorized_keys
</code></pre>

<p>Paste your public key and save, set proper chmod</p>

<pre><code>chmod 700 .ssh -R
</code></pre>

<p>logout and check if you can log in as NONPRIVILAGEUNIXUSERNAME directly without password</p>

<pre><code>ssh NONPRIVILAGEUNIXUSERNAME@SERVERIPADDRESS
</code></pre>

<h3>Disable log in with password (you will use public key anyway)</h3>

<pre><code>sudo passwd -l NONPRIVILAGEUNIXUSERNAME
</code></pre>

<p>This command locks the password</p>

<h3>Color prompt (optional)</h3>

<pre><code>nano ~/.bashrc
</code></pre>

<p>Uncomment following line (remove #)</p>

<pre><code>#force_color_prompt=yes
</code></pre>

<h3>fail2ban - solution for brute force attacks</h3>

<pre><code>sudo apt-get install fail2ban
</code></pre>

<h3>Disable direct log in on root account</h3>

<pre><code>sudo nano /etc/ssh/sshd_config
</code></pre>

<p>Find and change from <strong>yes</strong> to <strong>no</strong> (Ctrl + W in nano)</p>

<pre><code>PermitRootLogin no
</code></pre>

<h3>We will need these to compile Node JS from sources later</h3>

<p>To do that install</p>

<pre><code>sudo apt-get update
sudo apt-get install -y gcc g++ make
</code></pre>

<h3>Server timezone</h3>

<pre><code>sudo dpkg-reconfigure tzdata
</code></pre>

<h3>Locale stuff</h3>

<p>Get rid of annoying errors when not using EN_US locale</p>

<blockquote>
  <p><a href="/blog/2014/06/22/fixing-locale-problem-debian">Fixing the locale problem in Debian</a></p>
</blockquote>

<h3>Change hostname to something better e.g. symfony-app-server (you cannot use dots)</h3>

<p>This step is optional</p>

<pre><code>sudo nano /etc/hostname
</code></pre>

<p>Put same host in /etc/hosts</p>

<pre><code>sudo nano /etc/hosts
</code></pre>

<p>restart server</p>

<pre><code>sudo reboot
</code></pre>

<h1 id="dotdeb">Dotdeb</h1>

<p>DotDeb is a reliable and up to date repository for most of packages required in web server</p>

<p>Instruction was copied from official DotDeb site <a href="http://www.dotdeb.org/instructions/">http://www.dotdeb.org/instructions/</a></p>

<p>First add the dotdeb repo to your sources.list file:</p>

<pre><code>sudo nano /etc/apt/sources.list
</code></pre>

<p>add this to the bottom of the file:</p>

<p>Debian 7.0 Wheezy</p>

<pre><code>deb http://packages.dotdeb.org wheezy all
deb-src http://packages.dotdeb.org wheezy all
</code></pre>

<p>or Debian 6.0 Squeeze</p>

<pre><code>deb http://packages.dotdeb.org squeeze all
deb-src http://packages.dotdeb.org squeeze all
</code></pre>

<p>If you want to install :</p>

<ul>
<li>PHP 5.5 on Debian 7.0 “Wheezy”, add these two lines too :</li>
</ul>

<pre><code>deb http://packages.dotdeb.org wheezy-php55 all
deb-src http://packages.dotdeb.org wheezy-php55 all
</code></pre>

<ul>
<li>PHP 5.4 on Debian 6.0 “Squeeze”, add these two lines too :</li>
</ul>

<pre><code>deb http://packages.dotdeb.org squeeze-php54 all
deb-src http://packages.dotdeb.org squeeze-php54 all
</code></pre>

<p>Next, add the GnuPG key to your distribution:</p>

<pre><code>wget http://www.dotdeb.org/dotdeb.gpg
cat dotdeb.gpg | sudo apt-key add -
</code></pre>

<p>Update APT:</p>

<pre><code class="bash">sudo apt-get update
</code></pre>

<h1 id="nginx">NGINX</h1>

<p>You probably won't need most of it features (like proxy, mail) so nginx-light should be enough. Latest stable release from dotdeb.org</p>

<pre><code class="bash">sudo apt-get install nginx-light
</code></pre>

<h3>NGINX - General Configuration</h3>

<p><strong>Note:</strong> set <code>worker_processes 2;</code> to the number of cpu cores your server has</p>

<pre><code>#/etc/nginx/nginx.conf
user www-data;
worker_processes 2;
pid /var/run/nginx.pid;

events {
    worker_connections 768;
}

http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    gzip on;
    gzip_disable "msie6";

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;
}
</code></pre>

<h3>NGINX - configuration specific for application</h3>

<p>create configuration file</p>

<pre><code class="bash">sudo nano /etc/nginx/sites-available/APPDOMAINNAME
</code></pre>

<p>edit #/etc/nginx/sites-available/APPDOMAINNAME</p>

<pre><code class="conf"># /etc/nginx/sites-available/APPDOMAINNAME
upstream php5-fpm {
    server unix:/var/run/php5-fpm.sock;
}

# redirect from www to non-www
server {
  listen 80;

  server_name www.APPDOMAINNAME;
  return 301 $scheme://APPDOMAINNAME$request_uri;
}

server {
  listen 80;

  server_name APPDOMAINNAME;
  root /var/www/APPDOMAINNAME/current/web;

  client_max_body_size 256M;

  # strip app.php/ prefix if it is present
  rewrite ^/app\.php/?(.*)$ /$1 permanent;

  location / {
    index app.php app_dev.php;
    try_files $uri @rewriteapp;
  }

  location @rewriteapp {
    rewrite ^(.*)$ /app.php/$1 last;
  }

  # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
  location ~ ^/(app|app_dev)\.php(/|$) {
    fastcgi_pass   php5-fpm;
    fastcgi_split_path_info ^(.+\.php)(/.*)$;
    include fastcgi_params;
    fastcgi_param  SCRIPT_FILENAME    $document_root$fastcgi_script_name;
    fastcgi_param  HTTPS              off;
  }
}
</code></pre>

<p>Enable site</p>

<pre><code class="bash">sudo ln -s /etc/nginx/sites-available/APPDOMAINNAME /etc/nginx/sites-enabled/APPDOMAINNAME
</code></pre>

<p>Remove default</p>

<pre><code>sudo rm /etc/nginx/sites-enabled/default
</code></pre>

<h1 id="php-fpm">PHP5-FPM</h1>

<p>Installing required packages</p>

<pre><code class="bash">sudo apt-get install -y php5 php5-fpm php-pear php5-common php5-mcrypt php5-mysql php5-cli php5-gd php5-intl php5-curl php5-dev
</code></pre>

<h3>pool.d/www.conf</h3>

<p><strong>Update (June 2014):</strong> since the time I created this guide php5-fpm team changed <code>/etc/php5/fpm/pool.d/www.conf</code> default settings to described below. You don't have to change anything from this section. I'm leaving it as a reference in case someone use old config.</p>

<p><strike>
Edit</p>

<pre><code># /etc/php5/fpm/pool.d/www.conf
</code></pre>

<p>Find and edit if needed user and group</p>

<pre><code>; Unix user/group of processes
; Note: The user is mandatory. If the group is not set, the default user's group
;       will be used.
user = www-data
group = www-data
</code></pre>

<p>Find and replace</p>

<pre><code>listen = 127.0.0.1:9000
</code></pre>

<p>with</p>

<pre><code>listen = /var/run/php5-fpm.sock
</code></pre>

<p></strike></p>

<h3>php.ini configuration</h3>

<p>FPM (used by web server - Nginx)</p>

<pre><code># /etc/php5/fpm/php.ini

date.timezone = Europe/Warsaw

short_open_tag = Off

expose_php = off

max_execution_time = 60

memory_limit = 256M

post_max_size = 128M
upload_max_filesize = 128M
</code></pre>

<p>CLI (used in console)</p>

<pre><code># /etc/php5/cli/php.ini

date.timezone = Europe/Warsaw

short_open_tag = Off
</code></pre>

<h3>Twig extension</h3>

<pre><code>sudo pear channel-discover pear.twig-project.org
sudo pear install twig/CTwig

sudo nano /etc/php5/mods-available/twig.ini
</code></pre>

<p>Paste inside</p>

<pre><code>extension=twig.so
</code></pre>

<h3>Zend OPCache</h3>

<pre><code>sudo pecl install zendopcache-7.0.2

sudo nano /etc/php5/mods-available/opcache.ini

# /etc/php5/mods-available/opcache.ini

zend_extension=/usr/lib/php5/20100525/opcache.so
opcache.memory_consumption=128
opcache.interned_strings_buffer=8
opcache.max_accelerated_files=4000
opcache.revalidate_freq=60
opcache.fast_shutdown=1
opcache.enable_cli=1

cd /etc/php5/conf.d
sudo ln -s ../mods-available/opcache.ini 05-opcache.ini
</code></pre>

<h3>APCu</h3>

<pre><code>git clone https://github.com/krakjoe/apcu
cd apcu
phpize
./configure
make
sudo make install

sudo nano /etc/php5/mods-available/apcu.ini

# /etc/php5/mods-available/apcu.ini

extension=apcu.so
apc.enabled=1
apc.shm_size=32M
apc.ttl=7200
apc.gc_ttl=3600
apc.enable_cli=0

cd /etc/php5/conf.d
sudo ln -s ../mods-available/apcu.ini 20-apcu.ini
</code></pre>

<h3>Restart PHP5-FPM</h3>

<p>For all changes to take an effect you need to restart php</p>

<pre><code>sudo service php5-fpm restart
</code></pre>

<h1 id="mysql">MySQL</h1>

<pre><code>sudo apt-get install -y mysql-server
</code></pre>

<p>In a window that popped up enter root password, use program like KeePassX to generate secure password</p>

<p><em>Tweak configuration</em></p>

<pre><code>sudo nano /etc/mysql/my.cnf
</code></pre>

<p>Add <em>innodb_file_per_table</em> right after <em>[mysqld]</em></p>

<pre><code>[mysqld]

innodb_file_per_table
</code></pre>

<p>Restart mysql for changes to take effect</p>

<pre><code>sudo service mysql restart
</code></pre>

<p>Next run and follow instructions</p>

<pre><code>sudo mysql_secure_installation
</code></pre>

<p>Install MySQL Workbench for secure managing your database over a SSH tunnel.
http://www.mysql.com/products/workbench/</p>

<p><em>DO NOT expose your mysql to outside world nor install web management tools like PhpMyAdmin, they were great few years ago. Now we have a better solutions.</em></p>

<h1 id="nodejs">Node JS</h1>

<blockquote>
  <p>I wrote a separate post about installing Node JS on Debian/Ubuntu</p>
  
  <p>You can find the post here: <a href="/blog/2014/06/22/how-to-install-node-js">How to install Node JS</a></p>
</blockquote>

<p><strike><strong>optional - I use it for compiling less files and minimizing javascripts with Uglify-JS</strong></strike></p>

<p>It's better to concat and minify assets before deployment. If you are working with multiple instances it will speed up deployment process by few seconds for each instance.</p>

<p>This is a common fact that NodeJS in Debian/Ubuntu is seriously outdated. Installing from source is nice and easy.</p>

<p><em>Install make and required compilers</em></p>

<pre><code>sudo apt-get update
sudo apt-get install -y gcc g++ make
</code></pre>

<p><em>Get source and install</em></p>

<p>Sadly there are no permalink for latest stable version so you are on your own with that. Go to http://nodejs.org/dist/latest/ and search for file matching the following pattern
<code>node-v0.10.*.tar.gz</code></p>

<pre><code>wget http://nodejs.org/dist/latest/node-v0.10.29.tar.gz
tar -zxvf node-v0.10.29.tar.gz
cd node-v0.10.29
./configure
make
sudo make install
</code></pre>

<p><em>Installing LESS compiler</em></p>

<pre><code>sudo npm install -g less
</code></pre>

<p><em>Installing uglify-js</em></p>

<pre><code>sudo npm install -g uglify-js
</code></pre>

<h3>GIT</h3>

<pre><code>sudo apt-get install -y git
</code></pre>

<h3>Remove Apache2, important!</h3>

<pre><code>sudo service apache2 stop
</code></pre>

<p>We don't need apache2 so remove it</p>

<pre><code>sudo apt-get remove apache2
</code></pre>

<p>Otherwise it will take 80 port after next reboot and nginx will not work</p>

<h3>User for deploying</h3>

<p>We will use www-data user to deploy code.</p>

<p>Add your public key</p>

<pre><code>sudo mkdir /var/www/.ssh -p
sudo nano /var/www/.ssh/authorized_keys
</code></pre>

<p><strong>It's super important that owner and group of whole .ssh should be root. This way with read permission user www-data will be able to read public key but won't be able to add new one or edit existing.</strong></p>

<p>With this we won't give www-data any more permissions than it already has.</p>

<h3>Directory for application</h3>

<pre><code>sudo mkdir /var/www/APPDOMAINNAME -p
sudo chown www-data:www-data /var/www/APPDOMAINNAME
</code></pre>

<h3>Deploying with Capifony</h3>

<p>This is super important step. Github allows only for 60 requests per hour for non authenticated connections. Using composer cache will prevent getting banned</p>

<pre><code>sudo mkdir /var/www/.composer
sudo chown www-data:www-data /var/www/.composer
</code></pre>

<p>Also a Curl is required if you are using Capifony for deployment</p>

<p>sudo apt-get install curl</p>

<h3>Test everything by restarting server</h3>

<pre><code>sudo reboot
</code></pre>

<h1>That's it!</h1>

<p>Thank you for taking time to read this guide.</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[Method &quot;getFlashes&quot; for object &quot;Symfony\Component\HttpFoundation\Session\Session&quot; does not exist]]></title>
            <link href="http://konradpodgorski.com/blog/2013/10/22/method-getflashes-for-object-symfony-slash-component-slash-httpfoundation-slash-session-slash-session-does-not-exist"/>
            <updated>2013-10-22T12:34:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2013/10/22/method-getflashes-for-object-symfony-slash-component-slash-httpfoundation-slash-session-slash-session-does-not-exist</id>
            <content type="html"><![CDATA[<p>Quick reference for people upgrading Symfony</p>

<p>Error</p>

<blockquote>
  <p>Method "getFlashes" for object "Symfony\Component\HttpFoundation\Session\Session" does not exist</p>
</blockquote>

<!-- more -->

<p>Change</p>

<pre><code>app.session.getFlashes()
</code></pre>

<p>to</p>

<pre><code>app.session.get('flashes')
</code></pre>

<p>Before</p>

<p></p>

<pre><code>    {% for key, message in app.session.getFlashes() %}
    &lt;div class="alert alert-{{ key }}" style="margin-top: 3px;"&gt;
        &lt;a class="close" data-dismiss="alert"&gt;×&lt;/a&gt;
        &lt;strong&gt;{{ ('alert_message.' ~ key)|trans }}&lt;/strong&gt; {{ message }}
    &lt;/div&gt;
    {% endfor %}
</code></pre>

<p></p>

<p>After change</p>

<p></p>

<pre><code>    {% for key, message in app.session.get('flashes') %}
    &lt;div class="alert alert-{{ key }}"&gt;
        &lt;a class="close" data-dismiss="alert"&gt;×&lt;/a&gt;
        &lt;strong&gt;{{ ('alert_message.' ~ key) | trans }}&lt;/strong&gt; {{ message | trans }}
    &lt;/div&gt;
    {% endfor %}
</code></pre>

<p></p>

<p>That's it</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How I migrated my blog from Wordpress to Octopress]]></title>
            <link href="http://konradpodgorski.com/blog/2013/10/21/how-i-migrated-my-blog-from-wordpress-to-octopress"/>
            <updated>2013-10-21T08:40:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2013/10/21/how-i-migrated-my-blog-from-wordpress-to-octopress</id>
            <content type="html"><![CDATA[<p>Yesterday I decided to try a markdown powered blog platform, Octopress with Github Pages hosting</p>

<p>Reason for this change is probably the same as yours, person who reads this</p>

<ul>
<li>Wordpress sucks at formatting code</li>
<li>Most of my "notes" and "readme" from various projects are markdown files, so if I decided to publish one of them, copy paste wasn't enough</li>
<li>3rd, and probably most important. "Hey, we are programmers" we can't use Wordpress ;-)</li>
</ul>

<!-- more -->

<p>If you have more reasons, fell free to give a comment below.</p>

<p><strong>This is not a complete guide, I decided to write few keypoints that could help others with migrating their Wordpress to Octopress.</strong></p>

<h2>Installing Octopress</h2>

<p><a href="/blog/2013/10/20/how-to-setup-octopress-on-ubuntu/">How to setup Octopress on Ubuntu</a></p>

<h2>Migrating permalinks</h2>

<p>On old Wordpress blog I had this permalink structure</p>

<pre><code>/blog/:id/:title
</code></pre>

<p>while it was ok back then, because I could modify title without loosing back links, with Octopress ids aren't used anymore.</p>

<p>I decided to go with standard permalink structure</p>

<pre><code>/blog/:year/:month/:day/:title
</code></pre>

<p>Ok, but problem is</p>

<p>Now it's time to get old Wordpress links working in Octopress</p>

<h2><a name="redirect-301-on-github-pages"></a>Redirect 301 on Github Pages, move old posts to the new permalink structure</h2>

<p>We want to keep old links working. Best solution would be 301 redirect all old posts.</p>

<p>Unfortunately this cannot be done the "HTTP way" by sending proper response headers (without JS) on Github pages. But there is a solution for that.</p>

<p>First, include an entire Wordpress blog in read only mode.</p>

<p>Dump an entire Wordpress blog to your disk using wget</p>

<p><a href="/blog/2013/10/20/how-to-recursively-download-an-entire-website-using-wget/">How to Recursively Download an Entire Website Using WGET</a></p>

<p>In my case all downloaded posts were in /blog directory, so to get them still working on Octopress I had to copy</p>

<pre><code>/wp-content
/blog
</code></pre>

<p>to</p>

<pre><code>/source/wp-content
/source/blog
</code></pre>

<p>If you used other permalink structure for instance</p>

<pre><code>/:title
</code></pre>

<p>You need to copy every directory, sorry! :(</p>

<p>Now edit each <code>/:title/index.html</code> file and put these inside <code>&lt;head&gt;</code></p>

<pre><code class="html">    &lt;meta http-equiv="refresh" content="0; url=http://konradpodgorski.com/blog/2013/10/21/how-i-migrated-my-blog-from-wordpress-to-octopress/"&gt;
    &lt;link rel="canonical" href="http://konradpodgorski.com/blog/2013/10/21/how-i-migrated-my-blog-from-wordpress-to-octopress/" /&gt;
</code></pre>

<p>Unfortunately you need to do this manually in most cases.</p>

<p>Using <code>&lt;meta http-equiv="refresh"</code> will redirect each visitor to the new post.
 As for Google Bot, it threats <code>&lt;link rel="canonical" href=</code> as 301 redirect, well.. not exactly but effect is that you get your pages reindexed and that is what you want.</p>

<p>Now there is no longer need to put any notice about the fact that this is archived post etc.</p>

<h3>Migrating comments</h3>

<p>I decided to go with Disqus</p>

<ol>
<li>Register on Disqus</li>
<li>On still working Wordpress blog change permalink structure to the same as your new Octopress blog (very important!)</li>
<li>With changed structure install "Disqus" plugin, log in and export current Comments.</li>
<li>Because we changed permalink structure all comments will get mapped to the one that will be used in Octopress</li>
</ol>

<p>edit _config.yml and enter your shortname</p>

<pre><code># Disqus Comments
disqus_short_name: konradpodgorski
disqus_show_comment_count: true
</code></pre>

<h3>That's it</h3>

<p>for now</p>
]]></content>
        </entry>
            <entry>
            <title type="html"><![CDATA[How to recursively download an entire website using WGET]]></title>
            <link href="http://konradpodgorski.com/blog/2013/10/20/how-to-recursively-download-an-entire-website-using-wget"/>
            <updated>2013-10-20T18:54:00+02:00</updated>
            <id>http://konradpodgorski.com/blog/2013/10/20/how-to-recursively-download-an-entire-website-using-wget</id>
            <content type="html"><![CDATA[<p>Wget snippet to recursively download an entire website using WGET</p>

<pre><code>wget http://example.com \
 --domains example.com \
 --recursive \
 --page-requisites \
 --no-clobber \
 --html-extension \
 --convert-links
</code></pre>

<!-- more -->

<p>Dump from wget --help for further reference</p>

<pre><code>Usage: wget [OPTION]... [URL]...

Mandatory arguments to long options are mandatory for short options too.

Startup:
  -V,  --version           display the version of Wget and exit.
  -h,  --help              print this help.
  -b,  --background        go to background after startup.
  -e,  --execute=COMMAND   execute a `.wgetrc'-style command.

Logging and input file:
  -o,  --output-file=FILE    log messages to FILE.
  -a,  --append-output=FILE  append messages to FILE.
  -d,  --debug               print lots of debugging information.
  -q,  --quiet               quiet (no output).
  -v,  --verbose             be verbose (this is the default).
  -nv, --no-verbose          turn off verboseness, without being quiet.
       --report-speed=TYPE   Output bandwidth as TYPE.  TYPE can be bits.
  -i,  --input-file=FILE     download URLs found in local or external FILE.
  -F,  --force-html          treat input file as HTML.
  -B,  --base=URL            resolves HTML input-file links (-i -F)
                             relative to URL.
       --config=FILE         Specify config file to use.

Download:
  -t,  --tries=NUMBER            set number of retries to NUMBER (0 unlimits).
       --retry-connrefused       retry even if connection is refused.
  -O,  --output-document=FILE    write documents to FILE.
  -nc, --no-clobber              skip downloads that would download to
                                 existing files (overwriting them).
  -c,  --continue                resume getting a partially-downloaded file.
       --progress=TYPE           select progress gauge type.
  -N,  --timestamping            don't re-retrieve files unless newer than
                                 local.
  --no-use-server-timestamps     don't set the local file's timestamp by
                                 the one on the server.
  -S,  --server-response         print server response.
       --spider                  don't download anything.
  -T,  --timeout=SECONDS         set all timeout values to SECONDS.
       --dns-timeout=SECS        set the DNS lookup timeout to SECS.
       --connect-timeout=SECS    set the connect timeout to SECS.
       --read-timeout=SECS       set the read timeout to SECS.
  -w,  --wait=SECONDS            wait SECONDS between retrievals.
       --waitretry=SECONDS       wait 1..SECONDS between retries of a retrieval.
       --random-wait             wait from 0.5*WAIT...1.5*WAIT secs between retrievals.
       --no-proxy                explicitly turn off proxy.
  -Q,  --quota=NUMBER            set retrieval quota to NUMBER.
       --bind-address=ADDRESS    bind to ADDRESS (hostname or IP) on local host.
       --limit-rate=RATE         limit download rate to RATE.
       --no-dns-cache            disable caching DNS lookups.
       --restrict-file-names=OS  restrict chars in file names to ones OS allows.
       --ignore-case             ignore case when matching files/directories.
  -4,  --inet4-only              connect only to IPv4 addresses.
  -6,  --inet6-only              connect only to IPv6 addresses.
       --prefer-family=FAMILY    connect first to addresses of specified family,
                                 one of IPv6, IPv4, or none.
       --user=USER               set both ftp and http user to USER.
       --password=PASS           set both ftp and http password to PASS.
       --ask-password            prompt for passwords.
       --no-iri                  turn off IRI support.
       --local-encoding=ENC      use ENC as the local encoding for IRIs.
       --remote-encoding=ENC     use ENC as the default remote encoding.
       --unlink                  remove file before clobber.

Directories:
  -nd, --no-directories           don't create directories.
  -x,  --force-directories        force creation of directories.
  -nH, --no-host-directories      don't create host directories.
       --protocol-directories     use protocol name in directories.
  -P,  --directory-prefix=PREFIX  save files to PREFIX/...
       --cut-dirs=NUMBER          ignore NUMBER remote directory components.

HTTP options:
       --http-user=USER        set http user to USER.
       --http-password=PASS    set http password to PASS.
       --no-cache              disallow server-cached data.
       --default-page=NAME     Change the default page name (normally
                               this is `index.html'.).
  -E,  --adjust-extension      save HTML/CSS documents with proper extensions.
       --ignore-length         ignore `Content-Length' header field.
       --header=STRING         insert STRING among the headers.
       --max-redirect          maximum redirections allowed per page.
       --proxy-user=USER       set USER as proxy username.
       --proxy-password=PASS   set PASS as proxy password.
       --referer=URL           include `Referer: URL' header in HTTP request.
       --save-headers          save the HTTP headers to file.
  -U,  --user-agent=AGENT      identify as AGENT instead of Wget/VERSION.
       --no-http-keep-alive    disable HTTP keep-alive (persistent connections).
       --no-cookies            don't use cookies.
       --load-cookies=FILE     load cookies from FILE before session.
       --save-cookies=FILE     save cookies to FILE after session.
       --keep-session-cookies  load and save session (non-permanent) cookies.
       --post-data=STRING      use the POST method; send STRING as the data.
       --post-file=FILE        use the POST method; send contents of FILE.
       --content-disposition   honor the Content-Disposition header when
                               choosing local file names (EXPERIMENTAL).
       --content-on-error      output the received content on server errors.
       --auth-no-challenge     send Basic HTTP authentication information
                               without first waiting for the server's
                               challenge.

HTTPS (SSL/TLS) options:
       --secure-protocol=PR     choose secure protocol, one of auto, SSLv2,
                                SSLv3, and TLSv1.
       --no-check-certificate   don't validate the server's certificate.
       --certificate=FILE       client certificate file.
       --certificate-type=TYPE  client certificate type, PEM or DER.
       --private-key=FILE       private key file.
       --private-key-type=TYPE  private key type, PEM or DER.
       --ca-certificate=FILE    file with the bundle of CA's.
       --ca-directory=DIR       directory where hash list of CA's is stored.
       --random-file=FILE       file with random data for seeding the SSL PRNG.
       --egd-file=FILE          file naming the EGD socket with random data.

FTP options:
       --ftp-user=USER         set ftp user to USER.
       --ftp-password=PASS     set ftp password to PASS.
       --no-remove-listing     don't remove `.listing' files.
       --no-glob               turn off FTP file name globbing.
       --no-passive-ftp        disable the "passive" transfer mode.
       --preserve-permissions  preserve remote file permissions.
       --retr-symlinks         when recursing, get linked-to files (not dir).

WARC options:
       --warc-file=FILENAME      save request/response data to a .warc.gz file.
       --warc-header=STRING      insert STRING into the warcinfo record.
       --warc-max-size=NUMBER    set maximum size of WARC files to NUMBER.
       --warc-cdx                write CDX index files.
       --warc-dedup=FILENAME     do not store records listed in this CDX file.
       --no-warc-compression     do not compress WARC files with GZIP.
       --no-warc-digests         do not calculate SHA1 digests.
       --no-warc-keep-log        do not store the log file in a WARC record.
       --warc-tempdir=DIRECTORY  location for temporary files created by the
                                 WARC writer.

Recursive download:
  -r,  --recursive          specify recursive download.
  -l,  --level=NUMBER       maximum recursion depth (inf or 0 for infinite).
       --delete-after       delete files locally after downloading them.
  -k,  --convert-links      make links in downloaded HTML or CSS point to
                            local files.
  -K,  --backup-converted   before converting file X, back up as X.orig.
  -m,  --mirror             shortcut for -N -r -l inf --no-remove-listing.
  -p,  --page-requisites    get all images, etc. needed to display HTML page.
       --strict-comments    turn on strict (SGML) handling of HTML comments.

Recursive accept/reject:
  -A,  --accept=LIST               comma-separated list of accepted extensions.
  -R,  --reject=LIST               comma-separated list of rejected extensions.
       --accept-regex=REGEX        regex matching accepted URLs.
       --reject-regex=REGEX        regex matching rejected URLs.
       --regex-type=TYPE           regex type (posix).
  -D,  --domains=LIST              comma-separated list of accepted domains.
       --exclude-domains=LIST      comma-separated list of rejected domains.
       --follow-ftp                follow FTP links from HTML documents.
       --follow-tags=LIST          comma-separated list of followed HTML tags.
       --ignore-tags=LIST          comma-separated list of ignored HTML tags.
  -H,  --span-hosts                go to foreign hosts when recursive.
  -L,  --relative                  follow relative links only.
  -I,  --include-directories=LIST  list of allowed directories.
  --trust-server-names             use the name specified by the redirection
                                   url last component.
  -X,  --exclude-directories=LIST  list of excluded directories.
  -np, --no-parent                 don't ascend to the parent directory.
</code></pre>
]]></content>
        </entry>
    </feed>